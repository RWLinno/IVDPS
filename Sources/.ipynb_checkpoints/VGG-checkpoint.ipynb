{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed94aefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Administrator\\\\FTP\\\\20230715'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e523ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc095b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(Reshape, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], -1)\n",
    "\n",
    "\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    blk = []\n",
    "    for i in range(num_convs):\n",
    "        if i == 0:\n",
    "            blk.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1,bias=False))\n",
    "        else:\n",
    "            blk.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1,bias=False))\n",
    "        blk.append(nn.ReLU())\n",
    "    blk.append(nn.MaxPool2d(kernel_size=2, stride=2)) # 这里会使宽高减半\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "def vgg(conv_arch, fc_features, fc_hidden_units):\n",
    "    net = nn.Sequential()\n",
    "    # 卷积层部分\n",
    "    for i, (num_convs, in_channels, out_channels) in enumerate(conv_arch):\n",
    "        # 每经过一个vgg_block都会使宽高减半\n",
    "        net.add_module(\"vgg_block_\" + str(i+1), vgg_block(num_convs, in_channels, out_channels))\n",
    "    # 全连接层部分\n",
    "    net.add_module(\"fc\", nn.Sequential(\n",
    "                                Reshape(),\n",
    "                                nn.Linear(fc_features, fc_hidden_units),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(fc_hidden_units, fc_hidden_units),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.5),\n",
    "                                nn.Linear(fc_hidden_units, 7)\n",
    "                                ))\n",
    "    return net\n",
    "\n",
    "conv_arch = ((1, 1, 32), (1, 32, 64), (2, 64, 128))\n",
    "# 经过5个vgg_block, 宽高会减半5次, 变成 224/32 = 7\n",
    "fc_features = 128 * 6* 6 # c * w * h\n",
    "fc_hidden_units = 1024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "661134c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.data[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c8dac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a433d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载FER2013数据集的CSV文件\n",
    "data = pd.read_csv('fer2013.csv')\n",
    "\n",
    "# 数据预处理和加载\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    emotion = data['emotion'][i]\n",
    "    pixels = data['pixels'][i].split()\n",
    "    image = Image.new('L', (48, 48))  # 创建灰度图像对象\n",
    "    image.putdata([int(p) for p in pixels])  # 将像素值填充到图像中\n",
    "\n",
    "    if data['Usage'][i] == 'Training':\n",
    "        train_data.append((image, emotion))\n",
    "    elif data['Usage'][i] == 'PublicTest':\n",
    "        test_data.append((image, emotion))\n",
    "    elif data['Usage'][i] == 'PrivateTest':\n",
    "        test_data.append((image, emotion))\n",
    "\n",
    "# 创建训练数据集和测试数据集\n",
    "train_dataset = CustomDataset(train_data, transform=transform)\n",
    "test_dataset = CustomDataset(test_data, transform=transform)\n",
    "\n",
    "# 创建训练数据集和测试数据集的加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed49218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d2437ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg(conv_arch, fc_features, fc_hidden_units)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df03ed4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Loss: 1.7568, Train Accuracy: 0.2854, Test Loss: 1.5898, Test Accuracy: 0.3665\n",
      "Epoch [2/20], Train Loss: 1.5062, Train Accuracy: 0.4124, Test Loss: 1.4160, Test Accuracy: 0.4564\n",
      "Epoch [3/20], Train Loss: 1.3721, Train Accuracy: 0.4721, Test Loss: 1.3591, Test Accuracy: 0.4712\n",
      "Epoch [4/20], Train Loss: 1.2704, Train Accuracy: 0.5166, Test Loss: 1.2947, Test Accuracy: 0.5049\n",
      "Epoch [5/20], Train Loss: 1.1879, Train Accuracy: 0.5509, Test Loss: 1.2324, Test Accuracy: 0.5300\n",
      "Epoch [6/20], Train Loss: 1.1043, Train Accuracy: 0.5861, Test Loss: 1.2282, Test Accuracy: 0.5369\n",
      "Epoch [7/20], Train Loss: 1.0190, Train Accuracy: 0.6162, Test Loss: 1.2498, Test Accuracy: 0.5397\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0.0\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    train_loss = train_loss / len(train_dataset)\n",
    "    train_accuracy = train_correct / len(train_dataset)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_correct = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    test_loss = test_loss / len(test_dataset)\n",
    "    test_accuracy = test_correct / len(test_dataset)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "        f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "        f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c75285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'model_vgg.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
